# DQN 埃尔登法环 AI 训练项目

一个基于深度Q网络(DQN)的埃尔登法环游戏AI训练项目，使用PyTorch实现，能够自动学习游戏策略并与Boss战斗。

## 🎮 项目简介

本项目实现了一个能够自主学习埃尔登法环游戏的AI智能体，通过深度强化学习技术，AI可以：

- 自动识别游戏画面和状态
- 学习最优的战斗策略
- 与Boss进行自主战斗
- 根据血量变化调整行为策略
- 处理各种游戏异常情况

## ✨ 主要功能

### 🧠 AI核心功能
- **深度Q网络(DQN)**：使用PyTorch实现的神经网络模型
- **经验回放**：存储和重放历史经验以提高学习效率
- **目标网络**：稳定训练过程的双网络结构
- **ε-贪婪策略**：平衡探索与利用的动作选择机制

### 🎯 游戏交互功能
- **实时屏幕捕获**：支持DXCam和Win32两种捕获方式
- **血量检测**：实时监控玩家和Boss血量变化
- **光标状态检测**：确保游戏控制的准确性
- **自动按键控制**：模拟键盘输入执行游戏动作

### 🛡️ 稳定性保障
- **异常处理**：自动处理游戏崩溃和异常情况
- **超时保护**：防止训练过程无限期卡死
- **模型备份**：自动保存训练进度和最佳模型
- **紧急重启**：多种重启策略应对不同情况

## 📋 系统要求

- **操作系统**：Windows 10/11
- **Python版本**：3.8+
- **GPU**：支持CUDA的NVIDIA显卡（推荐）
- **内存**：8GB以上
- **游戏**：埃尔登法环（需要已安装并可正常运行）

## 🚀 安装说明

### 1. 克隆项目
```bash
git clone <repository-url>
cd DQN_eldenring
```

### 2. 创建虚拟环境
```bash
python -m venv venv
venv\Scripts\activate  # Windows
```

### 3. 安装依赖
```bash
pip install -r requirements.txt
```

### 4. 安装额外依赖（可选）
如果需要使用DXCam进行更高效的屏幕捕获：
```bash
pip install dxcam-cpp
```

## 📖 使用方法

### 训练模式

1. **启动游戏**：确保埃尔登法环正在运行并处于合适的Boss战斗场景

2. **运行训练脚本**：
```bash
python DQN_eldenring_training_pytorch.py
```

3. **控制训练**：
   - 按 `T` 键暂停/继续训练
   - 训练过程会自动保存模型和日志

### 测试模式

运行已训练的模型进行测试：
```bash
python DQN_eldenring_test_pytorch.py
```

## 🎮 动作空间

当前支持的游戏动作：
- **动作0**：无操作（等待）
- **动作1**：攻击
- **动作2**：闪避
- **动作3**：锁定视角

## 📊 训练参数

### 网络结构
- **输入尺寸**：96×88像素灰度图像
- **卷积层**：2层卷积 + 池化
- **全连接层**：512 → 256 → 4（动作数）

### 超参数
- **学习率**：自适应调整
- **折扣因子(γ)**：0.9
- **探索率(ε)**：0.5 → 0.01
- **经验回放缓冲区**：2000条经验
- **批量大小**：16（小批次）/ 128（大批次）

## 📁 项目结构

```
DQN_eldenring/
├── DQN_eldenring_training_pytorch.py  # 主训练脚本
├── DQN_eldenring_test_pytorch.py      # 测试脚本
├── DQN_pytorch_gpu.py                 # DQN模型实现
├── directkeys.py                      # 按键控制模块
├── getkeys.py                         # 按键检测模块
├── restart.py                         # 重启控制模块
├── requirements.txt                   # 依赖列表
├── logo.png                          # 游戏窗口识别图标
├── model_gpu/                        # 模型保存目录
│   ├── pytorch_model.pth             # 主模型文件
│   └── pytorch_model_episode_*.pth   # 特定回合模型
└── venv/                             # 虚拟环境
```

## 🔧 配置说明

### 屏幕捕获配置
```python
USE_WIN32_FALLBACK = True  # 是否使用Win32备用方案
game_width = 1280          # 游戏窗口宽度
game_height = 720          # 游戏窗口高度
```

### 血量检测区域
```python
REGIONS = {
    'self_blood': (105, 34, 632, 35),    # 玩家血条区域
    'boss_blood': (310, 580, 969, 580)   # Boss血条区域
}
```

## 📈 训练监控

训练过程中会输出以下信息：
- 当前回合数和存活步数
- 玩家和Boss血量变化
- 动作选择和奖励值
- 模型保存状态
- 异常处理情况

## 🎯 奖励机制

- **对Boss造成伤害**：正奖励
- **受到伤害**：负奖励
- **存活时间**：持续小额正奖励
- **击败Boss**：大额正奖励
- **死亡**：大额负奖励

## 🛠️ 故障排除

### 常见问题

1. **无法捕获游戏画面**
   - 确保游戏以窗口模式运行
   - 检查游戏窗口尺寸设置
   - 尝试切换屏幕捕获方式

2. **按键控制无效**
   - 确保游戏窗口处于活动状态
   - 检查按键映射配置
   - 以管理员权限运行脚本

3. **训练不稳定**
   - 调整学习率和批量大小
   - 检查奖励函数设计
   - 增加训练回合数

### 性能优化

- 使用GPU加速训练（推荐NVIDIA RTX系列）
- 调整图像处理分辨率
- 优化屏幕捕获方式
- 合理设置训练参数

## 📝 更新日志

- **v1.0**：基础DQN实现和游戏交互
- **v1.1**：添加GPU支持和性能优化
- **v1.2**：改进异常处理和稳定性
- **v1.3**：优化奖励机制和训练效果

## 🤝 贡献指南

欢迎提交Issue和Pull Request来改进项目！

## ⚖️ 免责声明

本项目仅用于学习和研究目的，请遵守游戏服务条款和相关法律法规。使用本项目产生的任何后果由用户自行承担。

## 📄 许可证

本项目采用MIT许可证，详见LICENSE文件。

---

**享受AI学习的乐趣！** 🎮🤖